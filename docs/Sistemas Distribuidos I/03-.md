# paralelizacion, multicomputing y direccionamiento

paralelizar
- para aprovechar los recursos fisicos
- reducir tiempo de computo de una tarea(latencia)
- incrementar la cantidad de tareas que se pueden realizar en paralelo(throughput). capaz puedo hacer mas
- reducir costes de energia
- camino critico: maxima long de tareas secuenciales a computar. No todas las tareas las puedo hacer al mismo tiempo. en esa dependencia tengo un conjunto de tareas que tienen mas cantidad de tareas(cmino critico).
	- Define el mejor rendimiento que se puede obtener al realizar un conjunto de tareas

## LEY DE AMDAHL
- todo trabajo de computo se divide en fracciones secuenciales y paralelas
![[Sistemas Distribuidos I/Pasted image 20250318200127.png]]

- la parte serial no la puedo dividir.

![[Sistemas Distribuidos I/Pasted image 20250318200210.png]]

- si tengo un solo proc hago la parte serial primero.
- la parte paralelizable la hago en varios procesadores

- lo max que tardo es con un solo procesador
- si tengo infinita paralelizacion, me queda 1/f -> esto es lo mejor que puedo lograr

![[Sistemas Distribuidos I/img/Pasted image 20250318200442.png]]

- la primera mejora es buenisima.
- a medida que se mejora el ultimo tramo, mas pesa la parte serializable.
- todo trabajo que hagas, esta despediciado si tenes una parte serial(no se puede mejorar).
- no siempre agregando mas recursos se mejora la solucion


gustafson
- si nos concentramos en paral, cuando tengo mas compus, no tendria que pensar en un solo problema.
- es demasiado generico(para mal)
	- si queremos describir un problema que haga computo util -> tengo dependencias, no puede hacer cualquier cosa en cualquier momento

en gral amdhal crece, y work-span se plancha en cierto punto

- multi computing -> cada proceso esta en una compu distinta y son mas indep
	- comparte menos recursos pero hay mas necesidad de sincronizacion

varias cpus
- varias quieren usar el mismo recurso a la vez
- hay tiempo desperdiciado -> comparten recursos

mimd(multiprocessors) memoria compartida
- colision entre procesadores para acceder a la memoria
- los procesadores se conectan mediante a un bridge
- NUMA acceso a memoria no uniforme. Cada CPU controla un bloque de memoria local como su home agent
	- PARECIIIIIIIIIDO A LA CACHE

multicomputing cable de red comparten
- mensajes se intercambian como se tienen que intercambiar(libertad)
	- necesidad de implementar mecanismos de sincronizacion
- limitacion de ancho de banda
- latencia y perdida de mensajes
- comunicacion entre procesos compleja y central al disenio de sistema
- alta escalabilidad y tolerantes a fallos

detallo los casos de uso(que quiero resolver)
diagramas de casos de uso

vista logica(clases, objetos y sus estados) documento logicamente como se disponen esas entidades identifico que esta pasando en el modelo

vista de desarrollo(componentes: elementos con I/O que se invocan entre si). Paquetes: estas entidades se packetizan de x manera. paquetes logicos de compilacion

vista de procesos(secuencia y actividad). lucha por recursos. procesos naturales del negocio

vista fisica. como se conectan los nodos que fui recolectando en las vistas anteriores. diagrama de robustez.

overview de que se trata la arqui
objetivos y limitaciones de la arqui
scenarios diagramas. ej de titulo: implementacion de modelo de workers para ejecucion de tareas. explico que hace
volumen y performance


c4 model
- me voy acercando de a poco al codigo

esto hizo roca en clase
![[Sistemas Distribuidos I/Pasted image 20250318215834.png]]


diagrama de despliegue
![[Sistemas Distribuidos I/Pasted image 20250318220000.png]]